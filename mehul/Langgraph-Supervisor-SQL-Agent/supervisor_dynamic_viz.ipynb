{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from typing import Callable, Literal, Optional, Sequence, Type, TypeVar, Union, cast\n",
    "from langchain_core.messages import AIMessage, BaseMessage, SystemMessage, ToolMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt.tool_node import ToolNode, tools_condition\n",
    "from langgraph.graph import MessagesState, START, END\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehulmathur/AI Projects/Langgraph-Supervisor-SQL-Agent/sql_react_agent.py:186: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(nl2sql_tool(\"I want to know the top ethnicities with the most part time employees\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSIDE NL2SQL TOOL\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msql_react_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nl2sql_tool, get_schema_info\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/sql_react_agent.py:186\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_schema_info\u001b[39m():\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m db.get_table_info()\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnl2sql_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mI want to know the top ethnicities with the most part time employees\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/_api/deprecation.py:188\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    186\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    187\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/tools/base.py:900\u001b[39m, in \u001b[36mBaseTool.__call__\u001b[39m\u001b[34m(self, tool_input, callbacks)\u001b[39m\n\u001b[32m    897\u001b[39m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m0.1.47\u001b[39m\u001b[33m\"\u001b[39m, alternative=\u001b[33m\"\u001b[39m\u001b[33minvoke\u001b[39m\u001b[33m\"\u001b[39m, removal=\u001b[33m\"\u001b[39m\u001b[33m1.0\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, tool_input: \u001b[38;5;28mstr\u001b[39m, callbacks: Callbacks = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    899\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Make tool callable.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m900\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/tools/base.py:775\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    774\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    776\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    777\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/tools/base.py:744\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    742\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m._run):\n\u001b[32m    743\u001b[39m         tool_kwargs = tool_kwargs | {config_param: config}\n\u001b[32m--> \u001b[39m\u001b[32m744\u001b[39m     response = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_format == \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    746\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) != \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/tools/structured.py:93\u001b[39m, in \u001b[36mStructuredTool._run\u001b[39m\u001b[34m(self, config, run_manager, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m.func):\n\u001b[32m     92\u001b[39m         kwargs[config_param] = config\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mStructuredTool does not support sync invocation.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/sql_react_agent.py:178\u001b[39m, in \u001b[36mnl2sql_tool\u001b[39m\u001b[34m(question)\u001b[39m\n\u001b[32m    169\u001b[39m chain = (\n\u001b[32m    170\u001b[39m     RunnablePassthrough.assign(\n\u001b[32m    171\u001b[39m         query=write_query | RunnableLambda(clean_sql_query)\n\u001b[32m   (...)\u001b[39m\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m )\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# Step 3: Run the chain\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m response = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mChain Response:\u001b[39m\u001b[33m\"\u001b[39m, response)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/runnables/base.py:3045\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3043\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3044\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3045\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3046\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3047\u001b[39m         \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/runnables/passthrough.py:514\u001b[39m, in \u001b[36mRunnableAssign.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    507\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    509\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    512\u001b[39m     **kwargs: Any,\n\u001b[32m    513\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m--> \u001b[39m\u001b[32m514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/runnables/base.py:1933\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1929\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1930\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1931\u001b[39m         output = cast(\n\u001b[32m   1932\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1933\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1935\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1936\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1937\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1938\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1939\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1940\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1941\u001b[39m         )\n\u001b[32m   1942\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1943\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/runnables/config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/runnables/passthrough.py:500\u001b[39m, in \u001b[36mRunnableAssign._invoke\u001b[39m\u001b[34m(self, input, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m    495\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    496\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)  \u001b[38;5;66;03m# noqa: TRY004\u001b[39;00m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    499\u001b[39m     **\u001b[38;5;28minput\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m500\u001b[39m     **\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    505\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/runnables/base.py:3776\u001b[39m, in \u001b[36mRunnableParallel.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3771\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3772\u001b[39m         futures = [\n\u001b[32m   3773\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3774\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3775\u001b[39m         ]\n\u001b[32m-> \u001b[39m\u001b[32m3776\u001b[39m         output = {key: \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[32m   3777\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3778\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/runnables/base.py:3760\u001b[39m, in \u001b[36mRunnableParallel.invoke.<locals>._invoke_step\u001b[39m\u001b[34m(step, input, config, key)\u001b[39m\n\u001b[32m   3754\u001b[39m child_config = patch_config(\n\u001b[32m   3755\u001b[39m     config,\n\u001b[32m   3756\u001b[39m     \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[32m   3757\u001b[39m     callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmap:key:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m   3758\u001b[39m )\n\u001b[32m   3759\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m-> \u001b[39m\u001b[32m3760\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3761\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3762\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3763\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3764\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/runnables/base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/runnables/base.py:5440\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5433\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5434\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5435\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5438\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5439\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5440\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5441\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5442\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5443\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5444\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:331\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m     **kwargs: Any,\n\u001b[32m    327\u001b[39m ) -> BaseMessage:\n\u001b[32m    328\u001b[39m     config = ensure_config(config)\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    330\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    341\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:894\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    885\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    887\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    891\u001b[39m     **kwargs: Any,\n\u001b[32m    892\u001b[39m ) -> LLMResult:\n\u001b[32m    893\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:719\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    718\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    725\u001b[39m         )\n\u001b[32m    726\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    727\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:960\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    958\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    959\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    963\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    964\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:955\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    953\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    954\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/_utils/_utils.py:279\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:914\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    873\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    911\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    912\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    913\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/_base_client.py:919\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    917\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/_base_client.py:1008\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1007\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1018\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[32m   1019\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err.response.is_closed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/_base_client.py:1057\u001b[39m, in \u001b[36mSyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[32m   1055\u001b[39m time.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/_base_client.py:1008\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1007\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1018\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[32m   1019\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err.response.is_closed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/_base_client.py:1057\u001b[39m, in \u001b[36mSyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[32m   1055\u001b[39m time.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1020\u001b[39m         err.response.read()\n\u001b[32m   1022\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1026\u001b[39m     cast_to=cast_to,\n\u001b[32m   1027\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1031\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1032\u001b[39m )\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from sql_react_agent import nl2sql_tool, get_schema_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LLM init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Agent State and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"The state of the agent.\"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "\n",
    "def create_agent(llm, tools):\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    def chatbot(state: AgentState):\n",
    "        return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "    graph_builder = StateGraph(AgentState)\n",
    "    graph_builder.add_node(\"agent\", chatbot)\n",
    "\n",
    "    tool_node = ToolNode(tools=tools)\n",
    "    graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "    graph_builder.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        tools_condition,\n",
    "    )\n",
    "    graph_builder.add_edge(\"tools\", \"agent\")\n",
    "    graph_builder.set_entry_point(\"agent\")\n",
    "    return graph_builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = get_schema_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clarify query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ClarifyToolSchema(BaseModel):\n",
    "    question: str\n",
    "\n",
    "def create_clarify_chain(llm, schema: str):\n",
    "    system_prompt = f\"\"\"\n",
    "You are a helpful assistant responsible for clarifying user queries related to a Microsoft SQL Server database.\n",
    "\n",
    "Here is the database schema:\n",
    "\n",
    "{schema}\n",
    "\n",
    "Your job is to rewrite the user query using the correct table and column names from the schema.\n",
    "Make the query as specific and unambiguous as possible while preserving the user's intent.\n",
    "Do not write an SQL query, just clarify the user's question using the schema information.\n",
    "For example, if the user asks \"What is the average salary?\", you might clarify it as \"What is the average salary of employees in the Employees table?\".\n",
    "\"\"\"\n",
    "\n",
    "    def clarify(question: str):\n",
    "        messages = [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=question)\n",
    "        ]\n",
    "        return llm.invoke(messages).content\n",
    "\n",
    "    return RunnableLambda(lambda x: clarify(x[\"question\"]))\n",
    "\n",
    "def clarify_tool_factory(llm, schema: str):\n",
    "    clarify_chain = create_clarify_chain(llm, schema)\n",
    "\n",
    "    @tool(args_schema=ClarifyToolSchema)\n",
    "    def clarify_query_tool(question: str) -> str:\n",
    "        \"\"\"Clarifies a natural language query by making it schema-aware.\"\"\"\n",
    "        print(\"INSIDE CLARIFY TOOL\")\n",
    "        return clarify_chain.invoke({\"question\": question})\n",
    "\n",
    "    return clarify_query_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_tool = clarify_tool_factory(llm, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SQL Sub-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl2sql_agent = create_agent(ChatOpenAI(model=\"gpt-4\"), [nl2sql_tool])\n",
    "\n",
    "def nl2sql_node(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = nl2sql_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"nl2sql\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clarify agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_agent = create_agent(ChatOpenAI(model=\"gpt-3.5-turbo-16k\"), [clarify_tool])\n",
    "\n",
    "def clarify_node(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = clarify_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"clarify\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define available agents\n",
    "members = [\"nl2sql\", \"clarify\"]\n",
    "# Add FINISH as an option for task completion\n",
    "options = members + [\"FINISH\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "   \"\"\"\n",
    "You are a supervisor agent named \"SQL Orchestrator\" tasked with managing a conversation between the following workers: {members}.\n",
    "Your role is to interpret user queries and delegate tasks to the appropriate worker based on the query's intent.\n",
    "\n",
    "Here is the database schema for your reference:\n",
    "{schema}\n",
    "\n",
    "Your responsibilities:\n",
    "1. If the user's query is ambiguous or does not clearly refer to tables or fields in the schema, route the query to the \"clarify\" worker first. It will rephrase the query using the database schema and return a clearer version.\n",
    "2. If the query is already clear and directly maps to the schema, route it to \"nl2sql\", which is capable of generating and executing SQL queries and returning results.\n",
    "3. Always think about wether to clarify the query, but ALWAYS then route to the \"nl2sql\" worker to obtain the results.\n",
    "4. Wait for the \"nl2sql\" agent to respond with the SQL query and/or its result.\n",
    "5. When returning the result to the user, include the column names and their data types. If the result is empty, mention that explicitly.\n",
    "6. Only delegate when necessary. When the task is complete and no further action is required, respond with `FINISH`.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPERVISOR_PROMPT = \"\"\"\n",
    "# You are a supervisor agent named \"SQL Orchestrator\". You are responsible for delegating user queries to a sub-agent called \"sql_react_agent\", which is capable of interacting with a Microsoft SQL Server database and returning query results.\n",
    "\n",
    "# Your job is to:\n",
    "# 1. Interpret the user's query and determine if it involves retrieving data from the database.\n",
    "# 2. Delegate that task to the \"SQL Agent\".\n",
    "# 3. Once the SQL Agent finishes its execution, analyze its full output history.\n",
    "# 4. From the output, extract:\n",
    "#    - The final result set returned by the SQL Agent.\n",
    "#    - The **column names** in the result.\n",
    "#    - The **data types** of those columns (if available or inferable).\n",
    "#    - How those columns and their values relate to the user's original question.\n",
    "\n",
    "# Only summarize information actually present in the SQL Agent's output — do not guess or fabricate columns, types, or values.\n",
    "\n",
    "# If no relevant information is found in the SQL Agent's output, reply that there was not enough information to answer the question.\n",
    "# \"\"\"\n",
    "\n",
    "# SUPERVISOR_PROMPT = \"\"\"\n",
    "# You are a supervisor agent named \"SQL Orchestrator\". You are responsible for delegating user queries to a sub-agent called \"sql_react_agent\", which is capable of interacting with a Microsoft SQL Server database and returning query results.\n",
    "\n",
    "# Your job is to:\n",
    "# 1. Interpret the user's query and determine if it involves retrieving data from the database.\n",
    "# 2. Delegate that task to the \"SQL Agent\".\n",
    "\n",
    "# If no relevant information is found in the SQL Agent's output, reply that there was not enough information to answer the question.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define router type for structured output\n",
    "class Router(TypedDict):\n",
    "    \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "    next: Literal[\"nl2sql\", \"clarify\", \"FINISH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create supervisor node function\n",
    "def supervisor_node(state: MessagesState) -> Command[Literal[\"nl2sql\", \"clarify\", \"__end__\"]]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + state[\"messages\"]\n",
    "    response = llm.with_structured_output(Router).invoke(messages)\n",
    "    goto = response[\"next\"]\n",
    "    print(f\"Next Worker: {goto}\")\n",
    "    if goto == \"FINISH\":\n",
    "        goto = END\n",
    "    return Command(goto=goto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "builder.add_node(\"supervisor\", supervisor_node)\n",
    "builder.add_node(\"nl2sql\", nl2sql_node)\n",
    "builder.add_node(\"clarify\", clarify_node)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # You can put your exception handling code here\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehulmathur/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1637: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Worker: clarify\n",
      "((), {'supervisor': None})\n",
      "----\n",
      "INSIDE CLARIFY TOOL(('clarify:d29a9c41-2d24-1903-c11d-72851be1efc2',), {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_5i2FQ07CkV7yRAA1GfjKLoTJ', 'function': {'arguments': '{\\n  \"question\": \"top 3 most popular products in 2008\"\\n}', 'name': 'clarify_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 70, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-16k-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BJq4D1XDIN69OJ5vBMcBew0c1BvCC', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0d2160de-afd7-4ef0-83a0-e976f2471b7c-0', tool_calls=[{'name': 'clarify_query_tool', 'args': {'question': 'top 3 most popular products in 2008'}, 'id': 'call_5i2FQ07CkV7yRAA1GfjKLoTJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 70, 'output_tokens': 28, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "----\n",
      "\n",
      "(('clarify:d29a9c41-2d24-1903-c11d-72851be1efc2',), {'tools': {'messages': [ToolMessage(content='Here is the appropriate SQL query for your question:\\n\\n```SQL\\nSELECT TOP 3 \\n  P.ProductID,\\n  P.Name,\\n  COUNT(SOD.SalesOrderID) AS OrderCount\\nFROM \\n  SalesLT.Product AS P\\nJOIN \\n  SalesLT.SalesOrderDetail AS SOD ON P.ProductID = SOD.ProductID\\nJOIN \\n  SalesLT.SalesOrderHeader AS SOH ON SOD.SalesOrderID = SOH.SalesOrderID\\nWHERE \\n  YEAR(SOH.OrderDate) = 2008\\nGROUP BY \\n  P.ProductID,\\n  P.Name\\nORDER BY \\n  OrderCount DESC;\\n```\\n\\nThis query links the Product table with SalesOrderDetail and SalesOrderHeader to count the number of sales orders each product had in the year 2008. The products are then sorted in descending order by the order count and the top 3 are taken.', name='clarify_query_tool', id='5677d795-edd9-4ecc-a40c-90fc0fea6100', tool_call_id='call_5i2FQ07CkV7yRAA1GfjKLoTJ')]}})\n",
      "----\n",
      "(('clarify:d29a9c41-2d24-1903-c11d-72851be1efc2',), {'agent': {'messages': [AIMessage(content='I apologize, but I am not able to directly retrieve the name and prices of the 3 most popular products in 2008. However, I can help you with an SQL query that you can execute on a database to obtain the desired information. Here is the SQL query:\\n\\n```SQL\\nSELECT TOP 3 \\n  P.ProductName,\\n  P.Price\\nFROM \\n  Products P\\nJOIN \\n  Sales S ON P.ProductID = S.ProductID\\nWHERE \\n  YEAR(S.SaleDate) = 2008\\nGROUP BY \\n  P.ProductName,\\n  P.Price\\nORDER BY \\n  COUNT(*) DESC;\\n```\\n\\nPlease note that this query assumes you have a table called \"Products\" with columns \"ProductName\" and \"Price\", and a table called \"Sales\" with columns \"ProductID\" and \"SaleDate\". You may need to modify the table and column names in the query to match your specific database schema.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 192, 'prompt_tokens': 289, 'total_tokens': 481, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-16k-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BJq4OhWHP6W584krV1VKEJV2Nqxqa', 'finish_reason': 'stop', 'logprobs': None}, id='run-3ae5dc0b-0312-4bbf-a994-63ae15e212ab-0', usage_metadata={'input_tokens': 289, 'output_tokens': 192, 'total_tokens': 481, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "----\n",
      "((), {'clarify': {'messages': [HumanMessage(content='I apologize, but I am not able to directly retrieve the name and prices of the 3 most popular products in 2008. However, I can help you with an SQL query that you can execute on a database to obtain the desired information. Here is the SQL query:\\n\\n```SQL\\nSELECT TOP 3 \\n  P.ProductName,\\n  P.Price\\nFROM \\n  Products P\\nJOIN \\n  Sales S ON P.ProductID = S.ProductID\\nWHERE \\n  YEAR(S.SaleDate) = 2008\\nGROUP BY \\n  P.ProductName,\\n  P.Price\\nORDER BY \\n  COUNT(*) DESC;\\n```\\n\\nPlease note that this query assumes you have a table called \"Products\" with columns \"ProductName\" and \"Price\", and a table called \"Sales\" with columns \"ProductID\" and \"SaleDate\". You may need to modify the table and column names in the query to match your specific database schema.', additional_kwargs={}, response_metadata={}, name='clarify')]}})\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehulmathur/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1637: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Worker: nl2sql\n",
      "((), {'supervisor': None})\n",
      "----\n",
      "INSIDE NL2SQL TOOL(('nl2sql:ddadeb77-3f7f-fce0-99ce-48e936c9ed8f',), {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_o7FjpcQBvkW6dY82wdsrhkHy', 'function': {'arguments': '{\\n  \"question\": \"Can you give me the name and prices of 3 most popular products in 2008\"\\n}', 'name': 'nl2sql_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 267, 'total_tokens': 302, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BJq4TZt4V0tKuxDSIqWqDyN6u3ecX', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-961cd263-70af-4e4e-8264-9797c2e32d40-0', tool_calls=[{'name': 'nl2sql_tool', 'args': {'question': 'Can you give me the name and prices of 3 most popular products in 2008'}, 'id': 'call_o7FjpcQBvkW6dY82wdsrhkHy', 'type': 'tool_call'}], usage_metadata={'input_tokens': 267, 'output_tokens': 35, 'total_tokens': 302, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "----\n",
      "\n",
      "Query Execution Result: [('Sport-100 Helmet, Red', Decimal('34.9900')), ('Classic Vest, S', Decimal('63.5000')), ('Short-Sleeve Classic Jersey, XL', Decimal('53.9900'))]\n",
      "Chain Response: {'question': 'Can you give me the name and prices of 3 most popular products in 2008', 'query': 'SELECT TOP 3 P.[Name] AS ProductName, P.[ListPrice] AS ProductPrice \\nFROM [SalesLT].[Product] P \\nINNER JOIN [SalesLT].[SalesOrderDetail] SOD ON P.[ProductID] = SOD.[ProductID] \\nINNER JOIN [SalesLT].[SalesOrderHeader] SOH ON SOD.[SalesOrderID] = SOH.[SalesOrderID] \\nWHERE YEAR(SOH.[OrderDate]) = 2008 \\nGROUP BY P.[Name], P.[ListPrice] \\nORDER BY SUM(SOD.[OrderQty]) DESC', 'result': \"[('Sport-100 Helmet, Red', Decimal('34.9900')), ('Classic Vest, S', Decimal('63.5000')), ('Short-Sleeve Classic Jersey, XL', Decimal('53.9900'))]\"}\n",
      "(('nl2sql:ddadeb77-3f7f-fce0-99ce-48e936c9ed8f',), {'tools': {'messages': [ToolMessage(content='{\"question\": \"Can you give me the name and prices of 3 most popular products in 2008\", \"query\": \"SELECT TOP 3 P.[Name] AS ProductName, P.[ListPrice] AS ProductPrice \\\\nFROM [SalesLT].[Product] P \\\\nINNER JOIN [SalesLT].[SalesOrderDetail] SOD ON P.[ProductID] = SOD.[ProductID] \\\\nINNER JOIN [SalesLT].[SalesOrderHeader] SOH ON SOD.[SalesOrderID] = SOH.[SalesOrderID] \\\\nWHERE YEAR(SOH.[OrderDate]) = 2008 \\\\nGROUP BY P.[Name], P.[ListPrice] \\\\nORDER BY SUM(SOD.[OrderQty]) DESC\", \"result\": \"[(\\'Sport-100 Helmet, Red\\', Decimal(\\'34.9900\\')), (\\'Classic Vest, S\\', Decimal(\\'63.5000\\')), (\\'Short-Sleeve Classic Jersey, XL\\', Decimal(\\'53.9900\\'))]\"}', name='nl2sql_tool', id='529518ce-0a94-43de-8ff0-01ce05d5db77', tool_call_id='call_o7FjpcQBvkW6dY82wdsrhkHy')]}})\n",
      "----\n",
      "(('nl2sql:ddadeb77-3f7f-fce0-99ce-48e936c9ed8f',), {'agent': {'messages': [AIMessage(content='Here are the names and prices of the 3 most popular products in 2008:\\n\\n1. Sport-100 Helmet, Red - $34.99\\n2. Classic Vest, S - $63.50\\n3. Short-Sleeve Classic Jersey, XL - $53.99 \\n\\nThis data was fetched using the following SQL query:\\n```SQL\\nSELECT TOP 3 P.[Name] AS ProductName, P.[ListPrice] AS ProductPrice \\nFROM [SalesLT].[Product] P \\nINNER JOIN [SalesLT].[SalesOrderDetail] SOD ON P.[ProductID] = SOD.[ProductID] \\nINNER JOIN [SalesLT].[SalesOrderHeader] SOH ON SOD.[SalesOrderID] = SOH.[SalesOrderID] \\nWHERE YEAR(SOH.[OrderDate]) = 2008 \\nGROUP BY P.[Name], P.[ListPrice] \\nORDER BY SUM(SOD.[OrderQty]) DESC\\n```\\nPlease note this assumes specific table and column names which you might need to adjust according to your database schema.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 219, 'prompt_tokens': 513, 'total_tokens': 732, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BJq4bBy5wGjexrzM1bxHeBut6Ejhh', 'finish_reason': 'stop', 'logprobs': None}, id='run-022eb604-b177-4452-9392-f8d67100a7f4-0', usage_metadata={'input_tokens': 513, 'output_tokens': 219, 'total_tokens': 732, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "----\n",
      "((), {'nl2sql': {'messages': [HumanMessage(content='Here are the names and prices of the 3 most popular products in 2008:\\n\\n1. Sport-100 Helmet, Red - $34.99\\n2. Classic Vest, S - $63.50\\n3. Short-Sleeve Classic Jersey, XL - $53.99 \\n\\nThis data was fetched using the following SQL query:\\n```SQL\\nSELECT TOP 3 P.[Name] AS ProductName, P.[ListPrice] AS ProductPrice \\nFROM [SalesLT].[Product] P \\nINNER JOIN [SalesLT].[SalesOrderDetail] SOD ON P.[ProductID] = SOD.[ProductID] \\nINNER JOIN [SalesLT].[SalesOrderHeader] SOH ON SOD.[SalesOrderID] = SOH.[SalesOrderID] \\nWHERE YEAR(SOH.[OrderDate]) = 2008 \\nGROUP BY P.[Name], P.[ListPrice] \\nORDER BY SUM(SOD.[OrderQty]) DESC\\n```\\nPlease note this assumes specific table and column names which you might need to adjust according to your database schema.', additional_kwargs={}, response_metadata={}, name='nl2sql')]}})\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehulmathur/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1637: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Worker: FINISH\n",
      "((), {'supervisor': None})\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"Can you give me the name and prices of 3 most popular products in 2008\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]}, \n",
    "    subgraphs=True\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehulmathur/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1637: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Worker: clarify\n",
      "INSIDE CLARIFY TOOL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehulmathur/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1637: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Worker: nl2sql\n",
      "INSIDE NL2SQL TOOL\n",
      "Query Execution Result: [(71784, Decimal('119960.8240'))]\n",
      "Chain Response: {'question': 'What is the highest profitable sales order of all time?', 'query': 'SELECT TOP 1 [SalesOrderID], MAX([SubTotal] + [TaxAmt] + [Freight]) as [HighestProfit] \\nFROM [SalesLT].[SalesOrderHeader] \\nGROUP BY [SalesOrderID] \\nORDER BY [HighestProfit] DESC', 'result': \"[(71784, Decimal('119960.8240'))]\"}\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-vmt5O4SCmfAsWJWS68XkgySg on tokens per min (TPM): Limit 10000, Used 9866, Requested 484. Please try again in 2.1s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m input_question = \u001b[33m\"\u001b[39m\u001b[33mI want to know the highest profitable sales order of all time\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_question\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2688\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[39m\n\u001b[32m   2686\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2687\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m2688\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2689\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2692\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2693\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2694\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2695\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2696\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2697\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2698\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2340\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2334\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2335\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2336\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2337\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2338\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2339\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2340\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2341\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2342\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2343\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2344\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2345\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2346\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2347\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2348\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mnl2sql_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnl2sql_node\u001b[39m(state: MessagesState) -> Command[Literal[\u001b[33m\"\u001b[39m\u001b[33msupervisor\u001b[39m\u001b[33m\"\u001b[39m]]:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     result = \u001b[43mnl2sql_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Command(\n\u001b[32m      6\u001b[39m         update={\n\u001b[32m      7\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m         goto=\u001b[33m\"\u001b[39m\u001b[33msupervisor\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2688\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[39m\n\u001b[32m   2686\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2687\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m2688\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2689\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2692\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2693\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2694\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2695\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2696\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2697\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2698\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2340\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2334\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2335\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2336\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2337\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2338\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2339\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2340\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2341\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2342\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2343\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2344\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2345\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2346\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2347\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2348\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mcreate_agent.<locals>.chatbot\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchatbot\u001b[39m(state: AgentState):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/runnables/base.py:5440\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5433\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5434\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5435\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5438\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5439\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5440\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5441\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5442\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5443\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5444\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:331\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m     **kwargs: Any,\n\u001b[32m    327\u001b[39m ) -> BaseMessage:\n\u001b[32m    328\u001b[39m     config = ensure_config(config)\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    330\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    341\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:894\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    885\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    887\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    891\u001b[39m     **kwargs: Any,\n\u001b[32m    892\u001b[39m ) -> LLMResult:\n\u001b[32m    893\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:719\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    718\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    725\u001b[39m         )\n\u001b[32m    726\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    727\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:960\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    958\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    959\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    963\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    964\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:955\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    953\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    954\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/_utils/_utils.py:279\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:914\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    873\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    911\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    912\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    913\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/_base_client.py:919\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    917\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/_base_client.py:1008\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1007\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1018\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[32m   1019\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err.response.is_closed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/_base_client.py:1057\u001b[39m, in \u001b[36mSyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[32m   1055\u001b[39m time.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/_base_client.py:1008\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1007\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1018\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[32m   1019\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err.response.is_closed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/_base_client.py:1057\u001b[39m, in \u001b[36mSyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[32m   1055\u001b[39m time.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI Projects/Langgraph-Supervisor-SQL-Agent/langgraph-supervisor/lib/python3.13/site-packages/openai/_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1020\u001b[39m         err.response.read()\n\u001b[32m   1022\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1026\u001b[39m     cast_to=cast_to,\n\u001b[32m   1027\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1031\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1032\u001b[39m )\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-vmt5O4SCmfAsWJWS68XkgySg on tokens per min (TPM): Limit 10000, Used 9866, Requested 484. Please try again in 2.1s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "During task with name 'agent' and id '7ebf39d7-2ceb-ecdf-f538-b55f35f60a5c'",
      "During task with name 'nl2sql' and id '9d6334c3-f13f-a2e6-ea44-7fceb41bc609'"
     ]
    }
   ],
   "source": [
    "input_question = \"I want to know the highest profitable sales order of all time\"\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [(\"user\", input_question)]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mresult\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator_agent = create_supervisor(\n",
    "    agents=[SQL_REACT_AGENT],\n",
    "    model=llm,\n",
    "    prompt=(\n",
    "        SUPERVISOR_PROMPT\n",
    "    ),\n",
    "    output_mode=\"last_message\",\n",
    "    # output_mode=\"full_history\",\n",
    "    supervisor_name=\"SQL_Orchestrator\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_app = orchestrator_agent.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(nodes={'__start__': Node(id='__start__', name='__start__', data=<class 'langchain_core.utils.pydantic.LangGraphInput'>, metadata=None), 'SQL_Orchestrator': Node(id='SQL_Orchestrator', name='SQL_Orchestrator', data=<langgraph.graph.state.CompiledStateGraph object at 0x12098efd0>, metadata=None), 'sql_react_agent': Node(id='sql_react_agent', name='sql_react_agent', data=call_agent(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), '__end__': Node(id='__end__', name='__end__', data=<class 'langchain_core.utils.pydantic.LangGraphOutput'>, metadata=None)}, edges=[Edge(source='__start__', target='SQL_Orchestrator', data=None, conditional=False), Edge(source='sql_react_agent', target='SQL_Orchestrator', data=None, conditional=False), Edge(source='SQL_Orchestrator', target='sql_react_agent', data=None, conditional=True), Edge(source='SQL_Orchestrator', target='__end__', data=None, conditional=True)])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_app.get_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        main_app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What are the top 3 most popular product categories', additional_kwargs={}, response_metadata={}, id='fd586410-3923-4005-820d-4b386b9f3e48'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_JcRAJV0yLf8YVKebINmiBL70', 'function': {'arguments': '{}', 'name': 'transfer_to_sql_react_agent'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 269, 'total_tokens': 281, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BJQ9uwdakdEV1jn9qzTsIf7hGyHv7', 'finish_reason': 'tool_calls', 'logprobs': None}, name='SQL_Orchestrator', id='run-157af403-7138-4fb7-ac34-8728cb2079e6-0', tool_calls=[{'name': 'transfer_to_sql_react_agent', 'args': {}, 'id': 'call_JcRAJV0yLf8YVKebINmiBL70', 'type': 'tool_call'}], usage_metadata={'input_tokens': 269, 'output_tokens': 12, 'total_tokens': 281, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Successfully transferred to sql_react_agent', name='transfer_to_sql_react_agent', id='047a7e03-b3aa-4746-9ca9-f47a4819e215', tool_call_id='call_JcRAJV0yLf8YVKebINmiBL70'),\n",
       "  AIMessage(content=\"I apologize for the inconvenience. It appears that there is an error caused by an invalid table name. Please ensure that all the table names used in our query are valid. \\n\\nIn terms of our process, we made an assumption about the structure of your database, tables, fields and relationships. This error suggests that our assumption is incorrect hence we can't proceed as is.\\n\\nCould you please provide the correct structure or guide us more specifically to answer the provided task?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 2548, 'total_tokens': 2642, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BJQAEuz0EZx4KZip7GWL8rgY1zY55', 'finish_reason': 'stop', 'logprobs': None}, name='sql_react_agent', id='run-c6ce03c6-0c22-4f6e-869e-ef369c354cf3-0', usage_metadata={'input_tokens': 2548, 'output_tokens': 94, 'total_tokens': 2642, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  AIMessage(content='Transferring back to SQL_Orchestrator', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='sql_react_agent', id='6639766d-38ed-42ff-b062-be6c6df9915c', tool_calls=[{'name': 'transfer_back_to_sql_orchestrator', 'args': {}, 'id': '32feb2d9-8906-4fdb-bf12-189acdf28954', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content='Successfully transferred back to SQL_Orchestrator', name='transfer_back_to_sql_orchestrator', id='6f493671-5ca0-444b-ba3b-f8b7aa277fc6', tool_call_id='32feb2d9-8906-4fdb-bf12-189acdf28954'),\n",
       "  AIMessage(content=\"The SQL agent was unable to execute the query due to an invalid or unknown table. Its request for more information about the database structure implies that it needs to know what tables hold the information about product categories and their popularity.\\n\\nThere wasn't enough information to answer the question in the SQL Agent's output. Further information about the database schema or a more specific query would be needed.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 469, 'total_tokens': 546, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BJQAHn9xsf1qDmd4G78a9hd6ftypU', 'finish_reason': 'stop', 'logprobs': None}, name='SQL_Orchestrator', id='run-82801ae1-068e-4507-8935-00b91146d5fb-0', usage_metadata={'input_tokens': 469, 'output_tokens': 77, 'total_tokens': 546, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = main_app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What are the top 3 most popular product categories\")]}\n",
    ")\n",
    "\n",
    "res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What are the top 3 most popular product categories', additional_kwargs={}, response_metadata={}, id='43a1ea5e-0425-4e7f-87be-9733c4fa7eed'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_x7PnNUKRDd8INviQuW1VmIqd', 'function': {'arguments': '{\\n  \"question\": \"What are the top 3 most popular product categories\"\\n}', 'name': 'nl2sql_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 62, 'total_tokens': 89, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BJSQh2odzgPpxQLFCTtVwl24vuJPd', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c7c38b46-ed5d-47b3-b8d8-30e891aa7992-0', tool_calls=[{'name': 'nl2sql_tool', 'args': {'question': 'What are the top 3 most popular product categories'}, 'id': 'call_x7PnNUKRDd8INviQuW1VmIqd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 62, 'output_tokens': 27, 'total_tokens': 89, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Error: NameError(\"name \\'llm\\' is not defined\")\\n Please fix your mistakes.', name='nl2sql_tool', id='fe59f72a-bee9-4eb5-a452-b4ef01490e24', tool_call_id='call_x7PnNUKRDd8INviQuW1VmIqd', status='error'),\n",
       "  AIMessage(content=\"I'm sorry but as a language model AI developed by OpenAI, I don't have capability to build and execute SQL queries. Here's a generic example of how you could structure the query:\\n\\n```sql\\nSELECT product_category, COUNT(*) as count\\nFROM sales_table\\nGROUP BY product_category\\nORDER BY count DESC\\nLIMIT 3\\n```\\n\\nIn this query, replace `sales_table` with the name of your database's sales table and `product_category` with the actual column's name in that table that represents product categories. This SQL command counts the number of occurrences of each category in the table (presumably each line summarizes one sale), groups the output by product category, orders it from the one with highest count to lowest and finally limits the output to top 3 lines/categories.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 162, 'prompt_tokens': 114, 'total_tokens': 276, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BJSQiwcQi3cEGip54RYRBsuqg9aOU', 'finish_reason': 'stop', 'logprobs': None}, id='run-f0851dd8-d615-47be-b92e-aa039a106c92-0', usage_metadata={'input_tokens': 114, 'output_tokens': 162, 'total_tokens': 276, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = nl2sql_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What are the top 3 most popular product categories\")]}\n",
    ")\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Can you give me the top 5 Sales orders by quantity?', additional_kwargs={}, response_metadata={}, id='cd660483-d43c-41eb-a35e-02e1b5d8b744')]}\n",
      "{'messages': [HumanMessage(content='Can you give me the top 5 Sales orders by quantity?', additional_kwargs={}, response_metadata={}, id='cd660483-d43c-41eb-a35e-02e1b5d8b744'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_2BvpXI7PEZFw2Qen9kTGoYeS', 'function': {'arguments': '{}', 'name': 'transfer_to_sql_react_agent'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 272, 'total_tokens': 287, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BJPyjHTboIAD3HlGLzbGnxhoVJLf3', 'finish_reason': 'tool_calls', 'logprobs': None}, name='SQL_Orchestrator', id='run-c1e536e9-16d9-4288-89c2-0e61a0e6cb88-0', tool_calls=[{'name': 'transfer_to_sql_react_agent', 'args': {}, 'id': 'call_2BvpXI7PEZFw2Qen9kTGoYeS', 'type': 'tool_call'}], usage_metadata={'input_tokens': 272, 'output_tokens': 15, 'total_tokens': 287, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Successfully transferred to sql_react_agent', name='transfer_to_sql_react_agent', id='b3da5c89-ce64-44ed-8ed4-43b98658280f', tool_call_id='call_2BvpXI7PEZFw2Qen9kTGoYeS')]}\n",
      "{'messages': [HumanMessage(content='Can you give me the top 5 Sales orders by quantity?', additional_kwargs={}, response_metadata={}, id='cd660483-d43c-41eb-a35e-02e1b5d8b744'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_2BvpXI7PEZFw2Qen9kTGoYeS', 'function': {'arguments': '{}', 'name': 'transfer_to_sql_react_agent'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 272, 'total_tokens': 287, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BJPyjHTboIAD3HlGLzbGnxhoVJLf3', 'finish_reason': 'tool_calls', 'logprobs': None}, name='SQL_Orchestrator', id='run-c1e536e9-16d9-4288-89c2-0e61a0e6cb88-0', tool_calls=[{'name': 'transfer_to_sql_react_agent', 'args': {}, 'id': 'call_2BvpXI7PEZFw2Qen9kTGoYeS', 'type': 'tool_call'}], usage_metadata={'input_tokens': 272, 'output_tokens': 15, 'total_tokens': 287, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Successfully transferred to sql_react_agent', name='transfer_to_sql_react_agent', id='b3da5c89-ce64-44ed-8ed4-43b98658280f', tool_call_id='call_2BvpXI7PEZFw2Qen9kTGoYeS'), AIMessage(content='Sure, I can help with that. However, I need a little more information about your database. Could you please let me know the names of the tables you have in your database? The required data could be spread across multiple tables.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 376, 'total_tokens': 425, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BJPym4TU1ictRHnq6NPLXStYPH3Oe', 'finish_reason': 'stop', 'logprobs': None}, name='sql_react_agent', id='run-9edb77ca-4ffc-4cc3-9a19-c6eb67a6fe2b-0', usage_metadata={'input_tokens': 376, 'output_tokens': 49, 'total_tokens': 425, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Transferring back to SQL_Orchestrator', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='sql_react_agent', id='236398b1-d2f6-4a41-b6e3-bac534553242', tool_calls=[{'name': 'transfer_back_to_sql_orchestrator', 'args': {}, 'id': '6ea74574-0e2b-4aeb-92ae-49686342c0b8', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to SQL_Orchestrator', name='transfer_back_to_sql_orchestrator', id='1a8a8e93-a866-44ff-bed2-661f07cd8f6e', tool_call_id='6ea74574-0e2b-4aeb-92ae-49686342c0b8')]}\n",
      "{'messages': [HumanMessage(content='Can you give me the top 5 Sales orders by quantity?', additional_kwargs={}, response_metadata={}, id='cd660483-d43c-41eb-a35e-02e1b5d8b744'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_2BvpXI7PEZFw2Qen9kTGoYeS', 'function': {'arguments': '{}', 'name': 'transfer_to_sql_react_agent'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 272, 'total_tokens': 287, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BJPyjHTboIAD3HlGLzbGnxhoVJLf3', 'finish_reason': 'tool_calls', 'logprobs': None}, name='SQL_Orchestrator', id='run-c1e536e9-16d9-4288-89c2-0e61a0e6cb88-0', tool_calls=[{'name': 'transfer_to_sql_react_agent', 'args': {}, 'id': 'call_2BvpXI7PEZFw2Qen9kTGoYeS', 'type': 'tool_call'}], usage_metadata={'input_tokens': 272, 'output_tokens': 15, 'total_tokens': 287, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Successfully transferred to sql_react_agent', name='transfer_to_sql_react_agent', id='b3da5c89-ce64-44ed-8ed4-43b98658280f', tool_call_id='call_2BvpXI7PEZFw2Qen9kTGoYeS'), AIMessage(content='Sure, I can help with that. However, I need a little more information about your database. Could you please let me know the names of the tables you have in your database? The required data could be spread across multiple tables.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 376, 'total_tokens': 425, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BJPym4TU1ictRHnq6NPLXStYPH3Oe', 'finish_reason': 'stop', 'logprobs': None}, name='sql_react_agent', id='run-9edb77ca-4ffc-4cc3-9a19-c6eb67a6fe2b-0', usage_metadata={'input_tokens': 376, 'output_tokens': 49, 'total_tokens': 425, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Transferring back to SQL_Orchestrator', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='sql_react_agent', id='236398b1-d2f6-4a41-b6e3-bac534553242', tool_calls=[{'name': 'transfer_back_to_sql_orchestrator', 'args': {}, 'id': '6ea74574-0e2b-4aeb-92ae-49686342c0b8', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to SQL_Orchestrator', name='transfer_back_to_sql_orchestrator', id='1a8a8e93-a866-44ff-bed2-661f07cd8f6e', tool_call_id='6ea74574-0e2b-4aeb-92ae-49686342c0b8'), AIMessage(content='There was not enough information to answer the question.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 433, 'total_tokens': 445, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BJPyoqzduHCx1jTknDC6PntK4DWbN', 'finish_reason': 'stop', 'logprobs': None}, name='SQL_Orchestrator', id='run-c7462eeb-1490-4245-8969-7f6359a2234b-0', usage_metadata={'input_tokens': 433, 'output_tokens': 12, 'total_tokens': 445, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the average salary of employees in the Sales department?', additional_kwargs={}, response_metadata={}, id='dbc1f029-8773-4217-b97b-8bc1262119c8'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_tX4dGr1gXhTXHN8qKGcEBDkH', 'function': {'arguments': '{}', 'name': 'transfer_to_sql_react_agent'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 271, 'total_tokens': 286, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BJPmyl9qhikFEEfna7bv3uRu9LhwX', 'finish_reason': 'tool_calls', 'logprobs': None}, name='SQL_Orchestrator', id='run-861f69d3-6deb-40ce-8a0a-b127b2923ec7-0', tool_calls=[{'name': 'transfer_to_sql_react_agent', 'args': {}, 'id': 'call_tX4dGr1gXhTXHN8qKGcEBDkH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 271, 'output_tokens': 15, 'total_tokens': 286, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Successfully transferred to sql_react_agent', name='transfer_to_sql_react_agent', id='3605cbfa-2b17-4da2-bee3-8d6b783195a6', tool_call_id='call_tX4dGr1gXhTXHN8qKGcEBDkH'),\n",
       "  AIMessage(content='To find the average salary of employees in the Sales department, we first need to understand the database schema. We need to know if there is a department field in the employee table, or if there is a separate department table. \\n\\nPlease give me some more time to understand your database better.', additional_kwargs={'tool_calls': [{'id': 'call_Jxr5BMSXbjJKtjszSZbiUfLb', 'function': {'arguments': '{}', 'name': 'sql_db_list_tables'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 375, 'total_tokens': 445, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BJPmyZyD5I96JnhHOFvpTmKnDOaZk', 'finish_reason': 'tool_calls', 'logprobs': None}, name='sql_react_agent', id='run-230bb69e-7228-4a74-b205-a904400bce13-0', tool_calls=[{'name': 'sql_db_list_tables', 'args': {}, 'id': 'call_Jxr5BMSXbjJKtjszSZbiUfLb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 375, 'output_tokens': 70, 'total_tokens': 445, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Address, Customer, CustomerAddress, Product, ProductCategory, ProductDescription, ProductModel, ProductModelProductDescription, SalesOrderDetail, SalesOrderHeader', name='sql_db_list_tables', id='61ef7e95-811e-42d6-813a-a391427bc45f', tool_call_id='call_Jxr5BMSXbjJKtjszSZbiUfLb'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_El2riOuaSP4ezWODva9ZHWzS', 'function': {'arguments': '{\\n  \"table_names\": \"Employee, Department\"\\n}', 'name': 'sql_db_schema'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 496, 'total_tokens': 516, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BJPn1ogpMjQeUCbCPYD9f92jbrYRl', 'finish_reason': 'tool_calls', 'logprobs': None}, name='sql_react_agent', id='run-2f5bc534-c2b9-40fd-9882-27c6e33298c4-0', tool_calls=[{'name': 'sql_db_schema', 'args': {'table_names': 'Employee, Department'}, 'id': 'call_El2riOuaSP4ezWODva9ZHWzS', 'type': 'tool_call'}], usage_metadata={'input_tokens': 496, 'output_tokens': 20, 'total_tokens': 516, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content=\"Error: table_names {'Department', 'Employee'} not found in database\", name='sql_db_schema', id='840f20ae-8940-4e62-bc4c-a0f40337a16b', tool_call_id='call_El2riOuaSP4ezWODva9ZHWzS'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_T5ILB06yFYmVUIA7aLG1NYDQ', 'function': {'arguments': '{\\n  \"table_names\": \"SalesOrderDetail, SalesOrderHeader\"\\n}', 'name': 'sql_db_schema'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 540, 'total_tokens': 564, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BJPn29XSqW0FKVWEEA2UWUs8vD6AX', 'finish_reason': 'tool_calls', 'logprobs': None}, name='sql_react_agent', id='run-20692fc7-ee74-4c6f-86a9-7b72e4ace755-0', tool_calls=[{'name': 'sql_db_schema', 'args': {'table_names': 'SalesOrderDetail, SalesOrderHeader'}, 'id': 'call_T5ILB06yFYmVUIA7aLG1NYDQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 540, 'output_tokens': 24, 'total_tokens': 564, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content=\"\\nCREATE TABLE [SalesLT].[SalesOrderDetail] (\\n\\t[SalesOrderID] INTEGER NOT NULL, \\n\\t[SalesOrderDetailID] INTEGER NOT NULL IDENTITY(1,1), \\n\\t[OrderQty] SMALLINT NOT NULL, \\n\\t[ProductID] INTEGER NOT NULL, \\n\\t[UnitPrice] MONEY NOT NULL, \\n\\t[UnitPriceDiscount] MONEY NOT NULL DEFAULT ((0.0)), \\n\\t[LineTotal] AS ((isnull(([UnitPrice]*((1.0)-[UnitPriceDiscount]))*[OrderQty],(0.0)))) NOT NULL, \\n\\trowguid UNIQUEIDENTIFIER NOT NULL DEFAULT (newid()), \\n\\t[ModifiedDate] DATETIME NOT NULL DEFAULT (getdate()), \\n\\tCONSTRAINT [PK_SalesOrderDetail_SalesOrderID_SalesOrderDetailID] PRIMARY KEY ([SalesOrderID], [SalesOrderDetailID]), \\n\\tCONSTRAINT [FK_SalesOrderDetail_Product_ProductID] FOREIGN KEY([ProductID]) REFERENCES [SalesLT].[Product] ([ProductID]), \\n\\tCONSTRAINT [FK_SalesOrderDetail_SalesOrderHeader_SalesOrderID] FOREIGN KEY([SalesOrderID]) REFERENCES [SalesLT].[SalesOrderHeader] ([SalesOrderID]) ON DELETE CASCADE\\n)\\n\\n/*\\n3 rows from SalesOrderDetail table:\\nSalesOrderID\\tSalesOrderDetailID\\tOrderQty\\tProductID\\tUnitPrice\\tUnitPriceDiscount\\tLineTotal\\trowguid\\tModifiedDate\\n71774\\t110562\\t1\\t836\\t356.8980\\t0.0000\\t356.898000\\te3a1994c-7a68-4ce8-96a3-77fdd3bbd730\\t2008-06-01 00:00:00\\n71774\\t110563\\t1\\t822\\t356.8980\\t0.0000\\t356.898000\\t5c77f557-fdb6-43ba-90b9-9a7aec55ca32\\t2008-06-01 00:00:00\\n71774\\t113408\\t2\\t707\\t50.0000\\t0.0000\\t100.000000\\t451daee2-7566-4fb5-953d-a800d8384fa9\\t2025-03-18 11:07:01.773000\\n*/\\n\\n\\nCREATE TABLE [SalesLT].[SalesOrderHeader] (\\n\\t[SalesOrderID] INTEGER NOT NULL DEFAULT (NEXT VALUE FOR [SalesLT].[SalesOrderNumber]), \\n\\t[RevisionNumber] TINYINT NOT NULL DEFAULT ((0)), \\n\\t[OrderDate] DATETIME NOT NULL DEFAULT (getdate()), \\n\\t[DueDate] DATETIME NOT NULL, \\n\\t[ShipDate] DATETIME NULL, \\n\\t[Status] TINYINT NOT NULL DEFAULT ((1)), \\n\\t[OnlineOrderFlag] BIT NOT NULL DEFAULT ((1)), \\n\\t[SalesOrderNumber] AS ((isnull(N'SO'+CONVERT([nvarchar](23),[SalesOrderID],(0)),N'*** ERROR ***'))) NOT NULL, \\n\\t[PurchaseOrderNumber] NVARCHAR(25) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \\n\\t[AccountNumber] NVARCHAR(15) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \\n\\t[CustomerID] INTEGER NOT NULL, \\n\\t[ShipToAddressID] INTEGER NULL, \\n\\t[BillToAddressID] INTEGER NULL, \\n\\t[ShipMethod] NVARCHAR(50) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL, \\n\\t[CreditCardApprovalCode] VARCHAR(15) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \\n\\t[SubTotal] MONEY NOT NULL DEFAULT ((0.00)), \\n\\t[TaxAmt] MONEY NOT NULL DEFAULT ((0.00)), \\n\\t[Freight] MONEY NOT NULL DEFAULT ((0.00)), \\n\\t[TotalDue] AS ((isnull(([SubTotal]+[TaxAmt])+[Freight],(0)))) NOT NULL, \\n\\t[Comment] NVARCHAR(max) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \\n\\trowguid UNIQUEIDENTIFIER NOT NULL DEFAULT (newid()), \\n\\t[ModifiedDate] DATETIME NOT NULL DEFAULT (getdate()), \\n\\tCONSTRAINT [PK_SalesOrderHeader_SalesOrderID] PRIMARY KEY ([SalesOrderID]), \\n\\tCONSTRAINT [FK_SalesOrderHeader_Address_BillTo_AddressID] FOREIGN KEY([BillToAddressID]) REFERENCES [SalesLT].[Address] ([AddressID]), \\n\\tCONSTRAINT [FK_SalesOrderHeader_Address_ShipTo_AddressID] FOREIGN KEY([ShipToAddressID]) REFERENCES [SalesLT].[Address] ([AddressID]), \\n\\tCONSTRAINT [FK_SalesOrderHeader_Customer_CustomerID] FOREIGN KEY([CustomerID]) REFERENCES [SalesLT].[Customer] ([CustomerID])\\n)\\n\\n/*\\n3 rows from SalesOrderHeader table:\\nSalesOrderID\\tRevisionNumber\\tOrderDate\\tDueDate\\tShipDate\\tStatus\\tOnlineOrderFlag\\tSalesOrderNumber\\tPurchaseOrderNumber\\tAccountNumber\\tCustomerID\\tShipToAddressID\\tBillToAddressID\\tShipMethod\\tCreditCardApprovalCode\\tSubTotal\\tTaxAmt\\tFreight\\tTotalDue\\tComment\\trowguid\\tModifiedDate\\n71774\\t2\\t2008-06-01 00:00:00\\t2008-06-13 00:00:00\\t2008-06-08 00:00:00\\t5\\tFalse\\tSO71774\\tPO348186287\\t10-4020-000609\\t29847\\t1092\\t1092\\tCARGO TRANSPORT 5\\tNone\\t880.3484\\t70.4279\\t22.0087\\t972.7850\\tNone\\t89e42cdc-8506-48a2-b89b-eb3e64e3554e\\t2008-06-08 00:00:00\\n71776\\t2\\t2008-06-01 00:00:00\\t2008-06-13 00:00:00\\t2008-06-08 00:00:00\\t5\\tFalse\\tSO71776\\tPO19952192051\\t10-4020-000106\\t30072\\t640\\t640\\tCARGO TRANSPORT 5\\tNone\\t78.8100\\t6.3048\\t1.9703\\t87.0851\\tNone\\t8a3448c5-e677-4158-a29b-dd33069be0b0\\t2008-06-08 00:00:00\\n71780\\t2\\t2008-06-01 00:00:00\\t2008-06-13 00:00:00\\t2008-06-08 00:00:00\\t5\\tFalse\\tSO71780\\tPO19604173239\\t10-4020-000340\\t30113\\t653\\t653\\tCARGO TRANSPORT 5\\tNone\\t38418.6895\\t3073.4952\\t960.4672\\t42452.6519\\tNone\\ta47665d2-7ac9-4cf3-8a8b-2a3883554284\\t2008-06-08 00:00:00\\n*/\", name='sql_db_schema', id='9513eb41-51c7-4360-91a0-77cb92b8828c', tool_call_id='call_T5ILB06yFYmVUIA7aLG1NYDQ'),\n",
       "  AIMessage(content=\"Based on the schema provided, I am unable to locate a field or table specifically pertaining to employee salaries or departments. The available tables are related to products, orders and customers. \\n\\nIf there are additional relevant tables in your schema, kindly provide their names or the correct names if any were misspelled. \\n\\nIn case I misunderstood your question, could you please provide more details or approximation of what you are looking for? \\n\\nPlease check your database for tables that would house this type of data - for example, 'Employee', 'Salary', 'Department', etc. It's also a possibility that the 'Sales' department may just be a category of a Product or a type of Order in the case of this schema.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 146, 'prompt_tokens': 2095, 'total_tokens': 2241, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BJPn4BtAKzeihp9nXIudwnQSilt1B', 'finish_reason': 'stop', 'logprobs': None}, name='sql_react_agent', id='run-481e12d4-4c8d-41ba-b4d4-42101111f289-0', usage_metadata={'input_tokens': 2095, 'output_tokens': 146, 'total_tokens': 2241, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  AIMessage(content='Transferring back to SQL_Orchestrator', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='sql_react_agent', id='3fae5e94-9ce1-4fec-a2f5-dbabd7725688', tool_calls=[{'name': 'transfer_back_to_sql_orchestrator', 'args': {}, 'id': 'f91512cb-522c-4492-bc38-36de732ec274', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content='Successfully transferred back to SQL_Orchestrator', name='transfer_back_to_sql_orchestrator', id='f5274d72-e40b-4dd3-a82b-7bdcdc83650f', tool_call_id='f91512cb-522c-4492-bc38-36de732ec274'),\n",
       "  AIMessage(content=\"Unfortunately, I couldn't find the necessary information in the database schema to calculate the average salary of employees in the Sales department. It seems that the database schema does not contain tables related to employees, salaries, or departments.\\n\\nIf you have another question related to the available tables like products, orders, or customers, feel free to ask!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 2256, 'total_tokens': 2325, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BJPn9YpHVY4AQRb8aOKsxAoMy5zSc', 'finish_reason': 'stop', 'logprobs': None}, name='SQL_Orchestrator', id='run-99768101-cd63-4b77-bee6-3c7f85314819-0', usage_metadata={'input_tokens': 2256, 'output_tokens': 69, 'total_tokens': 2325, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result = main_app.invoke(\n",
    "#     {\"messages\": [(\"user\", \"Can you give me the top 5 Sales orders by quantity?\")]}\n",
    "# )\n",
    "\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "\n",
    "query=\"Can you give me the top 5 Sales orders by quantity?\"\n",
    "\n",
    "events = main_app.stream(\n",
    "     {\"messages\": [HumanMessage(content=query)]},\n",
    "     stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "   print(event)\n",
    "#    message_content= event[\"messages\"][-1].content\n",
    "#    if \"Answer:\" in message_content:\n",
    "#       final_answer=message_content.split(\"Answer:\",1)[1].strip()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are the top 3 most popular product categories\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: sql_react_agent\n",
      "\n",
      "In order to answer that, I would need to execute a query on the database. Before making a query, I need to know the structure of your database. Let's start by getting the list of tables from your database.\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (call_HOdTjkwITEAbYNeF8rdbd7yq)\n",
      " Call ID: call_HOdTjkwITEAbYNeF8rdbd7yq\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_list_tables\n",
      "\n",
      "Address, Customer, CustomerAddress, Product, ProductCategory, ProductDescription, ProductModel, ProductModelProductDescription, SalesOrderDetail, SalesOrderHeader\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: sql_react_agent\n",
      "\n",
      "The database has tables like Product, ProductCategory, SalesOrderDetail which sound like they contain the information we need. Let's check the schema for these three tables to understand their structure.\n",
      "Tool Calls:\n",
      "  sql_db_schema (call_kEIodKCfEyiJ0UWdEavA9iCE)\n",
      " Call ID: call_kEIodKCfEyiJ0UWdEavA9iCE\n",
      "  Args:\n",
      "    table_names: Product, ProductCategory, SalesOrderDetail\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "CREATE TABLE [SalesLT].[ProductCategory] (\n",
      "\t[ProductCategoryID] INTEGER NOT NULL IDENTITY(1,1), \n",
      "\t[ParentProductCategoryID] INTEGER NULL, \n",
      "\t[Name] NVARCHAR(50) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL, \n",
      "\trowguid UNIQUEIDENTIFIER NOT NULL DEFAULT (newid()), \n",
      "\t[ModifiedDate] DATETIME NOT NULL DEFAULT (getdate()), \n",
      "\tCONSTRAINT [PK_ProductCategory_ProductCategoryID] PRIMARY KEY ([ProductCategoryID]), \n",
      "\tCONSTRAINT [FK_ProductCategory_ProductCategory_ParentProductCategoryID_ProductCategoryID] FOREIGN KEY([ParentProductCategoryID]) REFERENCES [SalesLT].[ProductCategory] ([ProductCategoryID])\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from ProductCategory table:\n",
      "ProductCategoryID\tParentProductCategoryID\tName\trowguid\tModifiedDate\n",
      "1\tNone\tBikes\tcfbda25c-df71-47a7-b81b-64ee161aa37c\t2002-06-01 00:00:00\n",
      "2\tNone\tComponents\tc657828d-d808-4aba-91a3-af2ce02300e9\t2002-06-01 00:00:00\n",
      "3\tNone\tClothing\t10a7c342-ca82-48d4-8a38-46a2eb089b74\t2002-06-01 00:00:00\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE [SalesLT].[Product] (\n",
      "\t[ProductID] INTEGER NOT NULL IDENTITY(1,1), \n",
      "\t[Name] NVARCHAR(50) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL, \n",
      "\t[ProductNumber] NVARCHAR(25) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL, \n",
      "\t[Color] NVARCHAR(15) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[StandardCost] MONEY NOT NULL, \n",
      "\t[ListPrice] MONEY NOT NULL, \n",
      "\t[Size] NVARCHAR(5) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[Weight] DECIMAL(8, 2) NULL, \n",
      "\t[ProductCategoryID] INTEGER NULL, \n",
      "\t[ProductModelID] INTEGER NULL, \n",
      "\t[SellStartDate] DATETIME NOT NULL, \n",
      "\t[SellEndDate] DATETIME NULL, \n",
      "\t[DiscontinuedDate] DATETIME NULL, \n",
      "\t[ThumbNailPhoto] VARBINARY(max) NULL, \n",
      "\t[ThumbnailPhotoFileName] NVARCHAR(50) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\trowguid UNIQUEIDENTIFIER NOT NULL DEFAULT (newid()), \n",
      "\t[ModifiedDate] DATETIME NOT NULL DEFAULT (getdate()), \n",
      "\tCONSTRAINT [PK_Product_ProductID] PRIMARY KEY ([ProductID]), \n",
      "\tCONSTRAINT [FK_Product_ProductCategory_ProductCategoryID] FOREIGN KEY([ProductCategoryID]) REFERENCES [SalesLT].[ProductCategory] ([ProductCategoryID]), \n",
      "\tCONSTRAINT [FK_Product_ProductModel_ProductModelID] FOREIGN KEY([ProductModelID]) REFERENCES [SalesLT].[ProductModel] ([ProductModelID])\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Product table:\n",
      "ProductID\tName\tProductNumber\tColor\tStandardCost\tListPrice\tSize\tWeight\tProductCategoryID\tProductModelID\tSellStartDate\tSellEndDate\tDiscontinuedDate\tThumbNailPhoto\tThumbnailPhotoFileName\trowguid\tModifiedDate\n",
      "680\tHL Road Frame - Black, 58\tFR-R92B-58\tBlack\t1059.3100\t1431.5000\t58\t1016.04\t18\t6\t2002-06-01 00:00:00\tNone\tNone\tb'GIF89aP\\x001\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x80\\x00\\x00\\x00\\x80\\x00\\x80\\x80\\x00\\x00\\x00\\x80\\x80\\x00\\x\tno_image_available_small.gif\t43dd68d6-14a4-461f-9069-55309d90ea7e\t2008-03-11 10:01:36.827000\n",
      "706\tHL Road Frame - Red, 58\tFR-R92R-58\tRed\t1059.3100\t1431.5000\t58\t1016.04\t18\t6\t2002-06-01 00:00:00\tNone\tNone\tb'GIF89aP\\x001\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x80\\x00\\x00\\x00\\x80\\x00\\x80\\x80\\x00\\x00\\x00\\x80\\x80\\x00\\x\tno_image_available_small.gif\t9540ff17-2712-4c90-a3d1-8ce5568b2462\t2008-03-11 10:01:36.827000\n",
      "707\tSport-100 Helmet, Red\tHL-U509-R\tRed\t13.0863\t34.9900\tNone\tNone\t35\t33\t2005-07-01 00:00:00\tNone\tNone\tb'GIF89aP\\x001\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x80\\x00\\x00\\x00\\x80\\x00\\x80\\x80\\x00\\x00\\x00\\x80\\x80\\x00\\x\tno_image_available_small.gif\t2e1ef41a-c08a-4ff6-8ada-bde58b64a712\t2008-03-11 10:01:36.827000\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE [SalesLT].[SalesOrderDetail] (\n",
      "\t[SalesOrderID] INTEGER NOT NULL, \n",
      "\t[SalesOrderDetailID] INTEGER NOT NULL IDENTITY(1,1), \n",
      "\t[OrderQty] SMALLINT NOT NULL, \n",
      "\t[ProductID] INTEGER NOT NULL, \n",
      "\t[UnitPrice] MONEY NOT NULL, \n",
      "\t[UnitPriceDiscount] MONEY NOT NULL DEFAULT ((0.0)), \n",
      "\t[LineTotal] AS ((isnull(([UnitPrice]*((1.0)-[UnitPriceDiscount]))*[OrderQty],(0.0)))) NOT NULL, \n",
      "\trowguid UNIQUEIDENTIFIER NOT NULL DEFAULT (newid()), \n",
      "\t[ModifiedDate] DATETIME NOT NULL DEFAULT (getdate()), \n",
      "\tCONSTRAINT [PK_SalesOrderDetail_SalesOrderID_SalesOrderDetailID] PRIMARY KEY ([SalesOrderID], [SalesOrderDetailID]), \n",
      "\tCONSTRAINT [FK_SalesOrderDetail_Product_ProductID] FOREIGN KEY([ProductID]) REFERENCES [SalesLT].[Product] ([ProductID]), \n",
      "\tCONSTRAINT [FK_SalesOrderDetail_SalesOrderHeader_SalesOrderID] FOREIGN KEY([SalesOrderID]) REFERENCES [SalesLT].[SalesOrderHeader] ([SalesOrderID]) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from SalesOrderDetail table:\n",
      "SalesOrderID\tSalesOrderDetailID\tOrderQty\tProductID\tUnitPrice\tUnitPriceDiscount\tLineTotal\trowguid\tModifiedDate\n",
      "71774\t110562\t1\t836\t356.8980\t0.0000\t356.898000\te3a1994c-7a68-4ce8-96a3-77fdd3bbd730\t2008-06-01 00:00:00\n",
      "71774\t110563\t1\t822\t356.8980\t0.0000\t356.898000\t5c77f557-fdb6-43ba-90b9-9a7aec55ca32\t2008-06-01 00:00:00\n",
      "71774\t113408\t2\t707\t50.0000\t0.0000\t100.000000\t451daee2-7566-4fb5-953d-a800d8384fa9\t2025-03-18 11:07:01.773000\n",
      "*/\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: sql_react_agent\n",
      "\n",
      "Based on the schema and sample data of the database tables, I can see that the `Product` table has a `ProductCategoryID` field which is a foreign key referencing `ProductCategoryID` in the `ProductCategory` table. The `SalesOrderDetail` table contains the amount of each product sold (`OrderQty`) and also has a `ProductID` field, which we can use to connect it with the `Product` table.\n",
      "\n",
      "Thus, the most popular product categories are those with the highest sums of `OrderQty` in the `SalesOrderDetail` table.\n",
      "\n",
      "Let's find the top 3 popular product categories by writing an SQL query. I'll check this query before executing it.\n",
      "Tool Calls:\n",
      "  sql_db_query_checker (call_POA13SvmNHUTEERXvIKuwsWO)\n",
      " Call ID: call_POA13SvmNHUTEERXvIKuwsWO\n",
      "  Args:\n",
      "    query: SELECT TOP 3 pc.Name, SUM(sod.OrderQty) as TotalQuantity FROM SalesOrderDetail sod JOIN Product p ON sod.ProductID = p.ProductID JOIN ProductCategory pc ON p.ProductCategoryID = pc.ProductCategoryID GROUP BY pc.Name ORDER BY TotalQuantity DESC\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query_checker\n",
      "\n",
      "SELECT TOP 3 pc.Name, SUM(sod.OrderQty) as TotalQuantity FROM SalesOrderDetail sod JOIN Product p ON sod.ProductID = p.ProductID JOIN ProductCategory pc ON p.ProductCategoryID = pc.ProductCategoryID GROUP BY pc.Name ORDER BY TotalQuantity DESC\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: sql_react_agent\n",
      "Tool Calls:\n",
      "  sql_db_query (call_0eRT1YN5lTslyvTTECoELfXr)\n",
      " Call ID: call_0eRT1YN5lTslyvTTECoELfXr\n",
      "  Args:\n",
      "    query: SELECT TOP 3 pc.Name, SUM(sod.OrderQty) as TotalQuantity FROM SalesOrderDetail sod JOIN Product p ON sod.ProductID = p.ProductID JOIN ProductCategory pc ON p.ProductCategoryID = pc.ProductCategoryID GROUP BY pc.Name ORDER BY TotalQuantity DESC\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query\n",
      "\n",
      "Error: (pyodbc.ProgrammingError) ('42S02', \"[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Invalid object name 'SalesOrderDetail'. (208) (SQLExecDirectW)\")\n",
      "[SQL: SELECT TOP 3 pc.Name, SUM(sod.OrderQty) as TotalQuantity FROM SalesOrderDetail sod JOIN Product p ON sod.ProductID = p.ProductID JOIN ProductCategory pc ON p.ProductCategoryID = pc.ProductCategoryID GROUP BY pc.Name ORDER BY TotalQuantity DESC]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: sql_react_agent\n",
      "\n",
      "It appears that there's an error because the \"SalesOrderDetail\" table was not found. Let me correct the table names by prefixing \"SalesLT.\", then reattempt the query. Let me double check this corrected query before running it.\n",
      "Tool Calls:\n",
      "  sql_db_query_checker (call_WZKaDM92yIoLdSZqQrjVUXum)\n",
      " Call ID: call_WZKaDM92yIoLdSZqQrjVUXum\n",
      "  Args:\n",
      "    query: SELECT TOP 3 pc.Name, SUM(sod.OrderQty) as TotalQuantity FROM SalesLT.SalesOrderDetail sod JOIN SalesLT.Product p ON sod.ProductID = p.ProductID JOIN SalesLT.ProductCategory pc ON p.ProductCategoryID = pc.ProductCategoryID GROUP BY pc.Name ORDER BY TotalQuantity DESC\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query_checker\n",
      "\n",
      "SELECT TOP 3 pc.Name, SUM(sod.OrderQty) as TotalQuantity \n",
      "FROM SalesLT.SalesOrderDetail sod \n",
      "JOIN SalesLT.Product p ON sod.ProductID = p.ProductID \n",
      "JOIN SalesLT.ProductCategory pc ON p.ProductCategoryID = pc.ProductCategoryID \n",
      "GROUP BY pc.Name \n",
      "ORDER BY TotalQuantity DESC\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: sql_react_agent\n",
      "Tool Calls:\n",
      "  sql_db_query (call_VCIFQGwN6UhnpG3vytklqiKy)\n",
      " Call ID: call_VCIFQGwN6UhnpG3vytklqiKy\n",
      "  Args:\n",
      "    query: SELECT TOP 3 pc.Name, SUM(sod.OrderQty) as TotalQuantity FROM SalesLT.SalesOrderDetail sod JOIN SalesLT.Product p ON sod.ProductID = p.ProductID JOIN SalesLT.ProductCategory pc ON p.ProductCategoryID = pc.ProductCategoryID GROUP BY pc.Name ORDER BY TotalQuantity DESC\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query\n",
      "\n",
      "[('Helmets', 459), ('Touring Bikes', 252), ('Jerseys', 230)]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: sql_react_agent\n",
      "\n",
      "The top 3 most popular product categories based on the quantity sold are:\n",
      "\n",
      "1. Helmets with a total of 459 sold\n",
      "2. Touring Bikes with a total of 252 sold\n",
      "3. Jerseys with a total of 230 sold\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "\n",
    "query=\"What are the top 3 most popular product categories\"\n",
    "\n",
    "events = SQL_REACT_AGENT.stream(\n",
    "     {\"messages\": [HumanMessage(content=query)]},\n",
    "     stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "   event[\"messages\"][-1].pretty_print()\n",
    "   message_content= event[\"messages\"][-1].content\n",
    "   if \"Answer:\" in message_content:\n",
    "      final_answer=message_content.split(\"Answer:\",1)[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-supervisor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
